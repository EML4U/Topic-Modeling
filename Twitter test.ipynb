{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/twitter/election_dataset.pickle', 'rb') as handle:\n",
    "    twitter = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden, trump = twitter['biden'], twitter['trump']\n",
    "biden_fe, trump_fe = twitter['biden_fe'], twitter['trump_fe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combi = [x for x in biden if 'trump' in x[1].lower()] + [x for x in trump if 'biden' in x[1].lower()]\n",
    "biden = [x for x in biden if 'trump' not in x[1].lower()]\n",
    "trump = [x for x in trump if 'biden' not in x[1].lower()]\n",
    "combi_fe = [x for x in biden_fe if 'trump' in x[1].lower()] + [x for x in trump_fe if 'biden' in x[1].lower()]\n",
    "biden_fe = [x for x in biden_fe if 'trump' not in x[1].lower()]\n",
    "trump_fe = [x for x in trump_fe if 'biden' not in x[1].lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from embedding import BertHuggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = BertHuggingface(8, model_name='bert-base-multilingual-cased', batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(data):\n",
    "    times, tweets = zip(*data)\n",
    "    embs = bert.embed(tweets)\n",
    "    z = zip(times, embs)\n",
    "    return list(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = 'data/twitter/biden_{}embeddings.pickle'\n",
    "\n",
    "if os.path.exists(pickle_path.format('')):\n",
    "    with open(pickle_path.format(''), 'rb') as handle:\n",
    "        embs_biden = pickle.load(handle)\n",
    "else:\n",
    "    embs_biden = embed(biden)\n",
    "    with open(pickle_path.format(''), 'wb') as handle:\n",
    "        pickle.dump(embs_biden, handle)\n",
    "print('biden embedding done...')\n",
    "\n",
    "if os.path.exists(pickle_path.format('fe_')):\n",
    "    with open(pickle_path.format('fe_'), 'rb') as handle:\n",
    "        embs_biden_fe = pickle.load(handle)\n",
    "else:\n",
    "    embs_biden_fe = embed(biden_fe)\n",
    "    with open(pickle_path.format('fe_'), 'wb') as handle:\n",
    "        pickle.dump(embs_biden, handle)\n",
    "print('biden_fe embedding done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = 'data/twitter/trump_{}embeddings.pickle'\n",
    "\n",
    "if os.path.exists(pickle_path.format('')):\n",
    "    with open(pickle_path.format(''), 'rb') as handle:\n",
    "        embs_trump = pickle.load(handle)\n",
    "else:\n",
    "    embs_trump = embed(trump)\n",
    "    with open(pickle_path.format(''), 'wb') as handle:\n",
    "        pickle.dump(embs_trump, handle)\n",
    "print('trump embedding done...')\n",
    "\n",
    "if os.path.exists(pickle_path.format('fe_')):\n",
    "    with open(pickle_path.format('fe_'), 'rb') as handle:\n",
    "        embs_trump_fe = pickle.load(handle)\n",
    "else:\n",
    "    embs_trump_fe = embed(trump_fe)\n",
    "    with open(pickle_path.format('fe_'), 'wb') as handle:\n",
    "        pickle.dump(embs_trump_fe, handle)\n",
    "print('trump embedding done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = 'data/twitter/combi_{}embeddings.pickle'\n",
    "\n",
    "if os.path.exists(pickle_path.format('')):\n",
    "    with open(pickle_path.format(''), 'rb') as handle:\n",
    "        embs_combi = pickle.load(handle)\n",
    "else:\n",
    "    embs_combi = embed(combi)\n",
    "    with open(pickle_path.format(''), 'wb') as handle:\n",
    "        pickle.dump(embs_combi, handle)\n",
    "print('combi embedding done...')\n",
    "\n",
    "if os.path.exists(pickle_path.format('fe_')):\n",
    "    with open(pickle_path.format('fe_'), 'rb') as handle:\n",
    "        embs_combi_fe = pickle.load(handle)\n",
    "else:\n",
    "    embs_combi_fe = embed(combi_fe)\n",
    "    with open(pickle_path.format('fe_'), 'wb') as handle:\n",
    "        pickle.dump(embs_combi_fe, handle)\n",
    "print('combi foreign embedding done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "def normalized(a, axis=-1, order=2):\n",
    "    l2 = np.atleast_1d(np.linalg.norm(a, order, axis))\n",
    "    l2[l2==0] = 1\n",
    "    return a / np.expand_dims(l2, axis)\n",
    "\n",
    "def create_moving_average(dataset, timeframe='hours'):\n",
    "    timefactor = 1 if timeframe == 'hours' else 24\n",
    "    moving_average = []\n",
    "    min_date = min([x[0] for x in dataset])\n",
    "    max_date = max([x[0] for x in dataset])\n",
    "    for each in range((max_date - min_date).days*(24 if timeframe == 'hours' else 1)):\n",
    "        d = min_date + datetime.timedelta(hours=each*timefactor)\n",
    "        points = [normalized(x[1]) for x in dataset if x[0] > d and x[0] < d + datetime.timedelta(hours=timefactor)]\n",
    "        if len(points):\n",
    "            moving_average.append(normalized(sum(points))) \n",
    "    return moving_average\n",
    "\n",
    "def count_entries(dataset, timeframe='hours', log=False):\n",
    "    timefactor = 1 if timeframe == 'hours' else 24\n",
    "    counts = []\n",
    "    min_date = min([x[0] for x in dataset])\n",
    "    max_date = max([x[0] for x in dataset])\n",
    "    for each in range((max_date - min_date).days*(24 if timeframe == 'hours' else 1)):\n",
    "        d = min_date + datetime.timedelta(hours=each*timefactor)\n",
    "        l = len([x for x in dataset if x[0] > d and x[0] < d + datetime.timedelta(hours=timefactor)])\n",
    "        if log and l > 0:\n",
    "            counts.append(np.log(l))\n",
    "        else:\n",
    "            counts.append(l)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "def compute_cosine_similarities(X):\n",
    "    cosine_similarities = []\n",
    "    for i in range(len(X)):\n",
    "        cosine_similarity = sklearn.metrics.pairwise.cosine_similarity(X[i], X[0])\n",
    "        cosine_similarities.append(cosine_similarity.item())\n",
    "        \n",
    "    return cosine_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet count by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, constrained_layout=True, figsize=(8,8))\n",
    "axs[0].plot(count_entries(biden, timeframe='days'))\n",
    "axs[0].set_title('Count of Biden tweets by day')\n",
    "axs[1].plot(count_entries(biden))\n",
    "axs[1].set_title('Count of Biden tweets by hour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, constrained_layout=True, figsize=(8,8))\n",
    "axs[0].plot(count_entries(trump, timeframe='days'))\n",
    "axs[0].set_title('Count of Trump tweets by day')\n",
    "axs[1].plot(count_entries(trump))\n",
    "axs[1].set_title('Count of Trump tweets by hour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, constrained_layout=True, figsize=(8,8))\n",
    "axs[0].plot(count_entries(biden_fe, timeframe='days'))\n",
    "axs[0].set_title('Count of foreign Biden tweets by day')\n",
    "axs[1].plot(count_entries(biden_fe))\n",
    "axs[1].set_title('Count of foreign Biden tweets by hour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, constrained_layout=True, figsize=(8,8))\n",
    "axs[0].plot(count_entries(trump_fe, timeframe='days'))\n",
    "axs[0].set_title('Count of foreign Trump tweets by day')\n",
    "axs[1].plot(count_entries(trump_fe))\n",
    "axs[1].set_title('Count of foreign Trump tweets by hour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, constrained_layout=True, figsize=(8,8))\n",
    "axs[0].plot(count_entries(combi, timeframe='days'))\n",
    "axs[0].set_title('Count of Combi tweets by day')\n",
    "axs[1].plot(count_entries(combi))\n",
    "axs[1].set_title('Count of Combi tweets by hour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, constrained_layout=True, figsize=(8,8))\n",
    "axs[0].plot(count_entries(combi_fe, timeframe='days'))\n",
    "axs[0].set_title('Count of foreign Combi tweets by day')\n",
    "axs[1].plot(count_entries(combi_fe))\n",
    "axs[1].set_title('Count of foreign Combi tweets by hour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, constrained_layout=True, figsize=(8,8))\n",
    "axs[0].plot(count_entries(biden, timeframe='days', log=True), color='xkcd:blue')\n",
    "axs[0].plot(count_entries(trump, timeframe='days', log=True), color='xkcd:red')\n",
    "axs[0].plot(count_entries(biden_fe, timeframe='days', log=True), color='xkcd:light blue')\n",
    "axs[0].plot(count_entries(trump_fe, timeframe='days', log=True), color='xkcd:light red')\n",
    "axs[0].plot(count_entries(combi, timeframe='days', log=True), color='xkcd:green')\n",
    "axs[0].plot(count_entries(combi_fe, timeframe='days', log=True), color='xkcd:light green')\n",
    "axs[0].set_title('Count of tweets by day')\n",
    "axs[1].plot(count_entries(biden, log=True), color='xkcd:blue')\n",
    "axs[1].plot(count_entries(trump, log=True), color='xkcd:red')\n",
    "axs[1].plot(count_entries(biden_fe, log=True), color='xkcd:light blue')\n",
    "axs[1].plot(count_entries(trump_fe, log=True), color='xkcd:light red')\n",
    "axs[1].plot(count_entries(combi, log=True), color='xkcd:green')\n",
    "axs[1].plot(count_entries(combi_fe, log=True), color='xkcd:light green')\n",
    "axs[1].set_title('Count of tweets by hour')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interesting points in time:\n",
    "#### Day 20: Day of the election (2020-11-04)\n",
    "What to expect:\n",
    "- More references to voting and appeal thereto\n",
    "- More \"I voted (blue | red | democrat | republican | biden | trump)\", \"Vote (biden | trump) today!\" etc\n",
    "\n",
    "#### Day 8: Last TV debate (2020-10-23 01:00) (GMT-2 apparently)\n",
    "- More references to TV and debating\n",
    "- More references to points and topics which came up in the debate like corona, iran & russia (election collusion), corruption (ukraine), north korea, healthcare, immigration, racism, climate (source [here](https://www.dw.com/en/trump-and-biden-square-off-in-final-debate-how-it-went/a-55364624))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarities by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_ma_hours = create_moving_average(embs_biden)\n",
    "biden_cos_hours = compute_cosine_similarities(biden_ma_hours)\n",
    "\n",
    "biden_ma_days = create_moving_average(embs_biden, timeframe='days')\n",
    "biden_cos_days = compute_cosine_similarities(biden_ma_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, constrained_layout=True, figsize=(8,8))\n",
    "axs[0].plot(biden_cos_days)\n",
    "axs[0].set_title('Similarity of Biden embeddings by day')\n",
    "axs[1].plot(biden_cos_hours)\n",
    "axs[1].set_title('Similarity of Biden embeddings by hour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_ma_hours_fe = create_moving_average(embs_biden_fe)\n",
    "biden_cos_hours_fe = compute_cosine_similarities(biden_ma_hours_fe)\n",
    "\n",
    "biden_ma_days_fe = create_moving_average(embs_biden_fe, timeframe='days')\n",
    "biden_cos_days_fe = compute_cosine_similarities(biden_ma_days_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, constrained_layout=True, figsize=(8,8))\n",
    "axs[0].plot(biden_cos_days_fe)\n",
    "axs[0].set_title('Similarity of foreign Biden embeddings by day')\n",
    "axs[1].plot(biden_cos_hours_fe)\n",
    "axs[1].set_title('Similarity of foreign Biden embeddings by hour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trump embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_ma_hours = create_moving_average(embs_trump)\n",
    "trump_cos_hours = compute_cosine_similarities(trump_ma_hours)\n",
    "\n",
    "trump_ma_days = create_moving_average(embs_trump, timeframe='days')\n",
    "trump_cos_days = compute_cosine_similarities(trump_ma_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, constrained_layout=True, figsize=(8,8))\n",
    "axs[0].plot(trump_cos_days)\n",
    "axs[0].set_title('Similarity of Trump embeddings by day')\n",
    "axs[1].plot(trump_cos_hours)\n",
    "axs[1].set_title('Similarity of Trump embeddings by hour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_ma_hours_fe = create_moving_average(embs_trump_fe)\n",
    "trump_cos_hours_fe = compute_cosine_similarities(trump_ma_hours_fe)\n",
    "\n",
    "trump_ma_days_fe = create_moving_average(embs_trump_fe, timeframe='days')\n",
    "trump_cos_days_fe = compute_cosine_similarities(trump_ma_days_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, constrained_layout=True, figsize=(8,8))\n",
    "axs[0].plot(trump_cos_days_fe)\n",
    "axs[0].set_title('Similarity of foreign Trump embeddings by day')\n",
    "axs[1].plot(trump_cos_hours_fe)\n",
    "axs[1].set_title('Similarity of foreign Trump embeddings by hour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined tweet similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combi_ma_hours = create_moving_average(embs_combi)\n",
    "combi_cos_hours = compute_cosine_similarities(combi_ma_hours)\n",
    "\n",
    "combi_ma_days = create_moving_average(embs_combi, timeframe='days')\n",
    "combi_cos_days = compute_cosine_similarities(combi_ma_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, constrained_layout=True, figsize=(8,8))\n",
    "axs[0].plot(combi_cos_days)\n",
    "axs[0].set_title('Similarity of Combi embeddings by day')\n",
    "axs[1].plot(combi_cos_hours)\n",
    "axs[1].set_title('Similarity of Combi embeddings by hour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combi_ma_hours_fe = create_moving_average(embs_combi_fe)\n",
    "combi_cos_hours_fe = compute_cosine_similarities(combi_ma_hours_fe)\n",
    "\n",
    "combi_ma_days_fe = create_moving_average(embs_combi_fe, timeframe='days')\n",
    "combi_cos_days_fe = compute_cosine_similarities(combi_ma_days_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, constrained_layout=True, figsize=(8,8))\n",
    "axs[0].plot(combi_cos_days_fe)\n",
    "axs[0].set_title('Similarity of foreign Combi embeddings by day')\n",
    "axs[1].plot(combi_cos_hours_fe)\n",
    "axs[1].set_title('Similarity of foreign Combi embeddings by hour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, constrained_layout=True, figsize=(8,8))\n",
    "axs[0].plot(biden_cos_days, color='xkcd:blue')\n",
    "axs[0].plot(trump_cos_days, color='xkcd:red')\n",
    "axs[0].plot(biden_cos_days_fe, color='xkcd:light blue')\n",
    "axs[0].plot(trump_cos_days_fe, color='xkcd:light red')\n",
    "axs[0].plot(combi_cos_days, color='xkcd:green')\n",
    "axs[0].plot(combi_cos_days_fe, color='xkcd:light green')\n",
    "axs[0].set_title('Similarity of tweets by day')\n",
    "axs[1].plot(biden_cos_hours, color='xkcd:blue')\n",
    "axs[1].plot(trump_cos_hours, color='xkcd:red')\n",
    "axs[1].plot(biden_cos_hours_fe, color='xkcd:light blue')\n",
    "axs[1].plot(trump_cos_hours_fe, color='xkcd:light red')\n",
    "axs[1].plot(combi_cos_hours, color='xkcd:green')\n",
    "axs[1].plot(combi_cos_hours_fe, color='xkcd:light green')\n",
    "axs[1].set_title('Similarity of tweets by hour')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trump_cos_hours.index([x for x in trump_cos_hours if x < 0.9825][0]))\n",
    "print(trump_cos_hours.index([x for x in trump_cos_hours if x < 0.9825][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min([x[0] for x in embs_trump]) + datetime.timedelta(hours=192))\n",
    "print(min([x[0] for x in embs_trump]) + datetime.timedelta(hours=486))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_tweets(data, amount=5):\n",
    "    data_r = data[1:]\n",
    "    maxes = []\n",
    "    for i in range(amount):\n",
    "        maxes.append(max(data_r))\n",
    "        data_r.remove(maxes[-1])\n",
    "    return [data.index(x) for x in maxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cosine differences for all points to mean at 100 and plot their histogram\n",
    "d = min([x[0] for x in embs_trump]) + datetime.timedelta(hours=100)\n",
    "points = [normalized(x[1]) for x in embs_trump if x[0] > d and x[0] < d + datetime.timedelta(hours=1)]\n",
    "combi_100 = [trump_ma_hours[100]]\n",
    "combi_100.extend(points)\n",
    "trump_100 = compute_cosine_similarities(combi_100)\n",
    "plt.hist(trump_100[1:])\n",
    "\n",
    "five_max = find_max_tweets(trump_100, amount=5)\n",
    "for i in range(5):\n",
    "    print([x for x in trump if x[0] > d and x[0] < d + datetime.timedelta(hours=1)][five_max[i]][1], trump_100[five_max[i]],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cosine differences for all points to mean at 480 and plot their histogram\n",
    "d = min([x[0] for x in embs_trump]) + datetime.timedelta(hours=480)\n",
    "points = [normalized(x[1]) for x in embs_trump if x[0] > d and x[0] < d + datetime.timedelta(hours=1)]\n",
    "combi_480 = [trump_ma_hours[480]]\n",
    "combi_480.extend(points)\n",
    "trump_480 = compute_cosine_similarities(combi_480)\n",
    "plt.hist(trump_480[1:])\n",
    "\n",
    "five_max = find_max_tweets(trump_480, amount=5)\n",
    "for i in range(5):\n",
    "    print([x for x in trump if x[0] > d and x[0] < d + datetime.timedelta(hours=1)][five_max[i]][1], trump_480[five_max[i]],'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### same with biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cosine differences for all points to mean at 100 and plot their histogram\n",
    "d = min([x[0] for x in embs_biden]) + datetime.timedelta(hours=100)\n",
    "points = [normalized(x[1]) for x in embs_biden if x[0] > d and x[0] < d + datetime.timedelta(hours=1)]\n",
    "combi_100 = [biden_ma_hours[100]]\n",
    "combi_100.extend(points)\n",
    "biden_100 = compute_cosine_similarities(combi_100)\n",
    "plt.hist(biden_100[1:])\n",
    "five_max = find_max_tweets(biden_100, amount=5)\n",
    "for i in range(5):\n",
    "    print([x for x in biden if x[0] > d and x[0] < d + datetime.timedelta(hours=1)][five_max[i]][1], biden_100[five_max[i]],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cosine differences for all points to mean at 480 and plot their histogram\n",
    "d = min([x[0] for x in embs_biden]) + datetime.timedelta(hours=480)\n",
    "points = [normalized(x[1]) for x in embs_biden if x[0] > d and x[0] < d + datetime.timedelta(hours=1)]\n",
    "combi_480 = [biden_ma_hours[480]]\n",
    "combi_480.extend(points)\n",
    "biden_480 = compute_cosine_similarities(combi_480)\n",
    "plt.hist(biden_480[1:])\n",
    "five_max = find_max_tweets(biden_480, amount=5)\n",
    "for i in range(5):\n",
    "    print([x for x in biden if x[0] > d and x[0] < d + datetime.timedelta(hours=1)][five_max[i]][1], biden_480[five_max[i]], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def load_sent_dataset(split = \"train\"):\n",
    "    ds = tfds.load('sentiment140', split=split, shuffle_files=False)\n",
    "    return ds\n",
    "\n",
    "def train_model(X,y,name= \"Sent_net\"):\n",
    "        \n",
    "        print(\"training model\", name)\n",
    "        X, X_test, y, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        loadModel = os.path.exists(name)\n",
    "        if not loadModel:\n",
    "            model = keras.Sequential()\n",
    "            model.add(keras.Input(shape=(X[0].shape)))\n",
    "            model.add(layers.Dense(100, activation=\"relu\"))\n",
    "            model.add(layers.Dense(50, activation=\"relu\"))\n",
    "            model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "            model.compile(optimizer=\"rmsprop\",loss='mse')\n",
    "            history = model.fit(X,y, epochs = 5, validation_data = (X_test,y_test), batch_size = 64,verbose = 3)\n",
    "        \n",
    "            model.save(name)\n",
    "        else:\n",
    "            model = keras.models.load_model(name)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "def preprocess_dataset(ds, encoder):\n",
    "    X = []\n",
    "    X_text= []\n",
    "    y= []\n",
    "    if not os.path.exists('data/embeded_twitter_ds.pkl'):\n",
    "        print(\"preprocessing dataset\")\n",
    "        for dicto in ds.take(100000):\n",
    "            X_text.append(str(dicto[\"text\"]))\n",
    "            y.append([float(dicto[\"polarity\"])/4.0])\n",
    "        print(True if [x for x in X_text if type(x)!=type('bla')] else False)\n",
    "        X = encoder.embed(X_text)\n",
    "        X, y = np.asarray(X), np.asarray(y)\n",
    "        file = open('data/embeded_twitter_ds.pkl', 'wb')\n",
    "        pickle.dump([X, y, X_text], file)\n",
    "    else:\n",
    "        file = open('data/embeded_twitter_ds.pkl', 'rb')\n",
    "        X, y, X_text = pickle.load(file)     \n",
    "    file.close()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('Sent_net_trained'):\n",
    "    ds = load_sent_dataset()\n",
    "    X, Y = preprocess_dataset(ds, bert)\n",
    "    with tf.device('/GPU:0'):\n",
    "        sentiment_model = train_model(X, Y)\n",
    "    sentiment_model.save('Sent_net_trained')\n",
    "else:\n",
    "    sentiment_model = keras.models.load_model('Sent_net_trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(data, model):\n",
    "    times, tweets = zip(*data)\n",
    "    embs = model.predict(tweets)\n",
    "    z = zip(times, embs)\n",
    "    return list(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('data/twitter_sentiments.pickle'):\n",
    "    with open('data/twitter/twitter_sentiments.pickle', 'rb') as handle:\n",
    "        biden_sentiment, trump_sentiment = pickle.load(handle)\n",
    "else:\n",
    "    print('sentimenting biden...')\n",
    "    biden_sentiment = predict_sentiment(embs_biden, sentiment_model)\n",
    "    print('sentimenting trump...')\n",
    "    trump_sentiment = predict_sentiment(embs_trump, sentiment_model)\n",
    "    with open('data/twitter/twitter_sentiments.pickle', 'wb') as handle:\n",
    "        pickle.dump((biden_sentiment, trump_sentiment), handle)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_sentiment[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markup of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# Trump tweets:', len(trump))\n",
    "print('# Biden tweets:', len(biden))\n",
    "print('# Both tweets:', len(combi))\n",
    "\n",
    "print('# foreign Trump tweets:', len(trump_fe))\n",
    "print('# foreign Biden tweets:', len(biden_fe))\n",
    "print('# foreign Both tweets:', len(combi_fe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
